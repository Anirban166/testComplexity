---
title: "Example vignette"
author: "Anirban Chetia"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Example vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

<p style="font-family: times, serif; font-size:25pt; font-style: italic" align="center">
Welcome to testComplexity
</p>

-------------------------------------------------------------------------------------------------

This vignette is written to give the user a general introduction to the features and functionality of the package, via a set of textual illustrations and one example.

## Brief Overview

As can be guessed from the name itself, this package provides a suite of functions to test the asymptotic complexities of R functions/algorithms, where the term "complexity" here refers to the *time* complexity, as per the initial idea. (and hence a relevant logo with the stopwatch was designed early on!) 

### Features

Going by the base objectives stated [here](https://github.com/rstats-gsoc/gsoc2020/wiki/Asymptotic-complexity-testing#details-of-your-coding-project), this package provides:

- A function for quantifying the empirical time complexity of any R expression. 
- A time complexity classifying function which operates on the result (a data frame) of the previous function.
- Testing functions, to test for an expected time complexity class directly.

In addition to these, a few more features have been implemented:
- Memory variants for the time quantifier and complexity classifier.
- Plotting functions for both time and memory cases.
- A complexity classifier for a generalized use in asymptotic trend classification among any two parameters, not being restricted to time/memory cases.

-------------------------------------------------------------------------------------------------

Based on whether the user has an idea of the complexity class the input algorithm falls in, two scenarios are possible:

- The complexity class of the algorithm is *not known*, or diagnostic tests to estimate it have not been performed yet. 
In this case, the user could directly use the [quantifiers](https://anirban166.github.io/testComplexity/articles/Example.html#quantifiers) and [complexity classifiers](https://anirban166.github.io/testComplexity/articles/Example.html#complexity-classifiers) to obtain the asymptotic complexity class. 
- The complexity class is *known* via theoretical proof/empirical observation. 
For this case, the user can directly proceed to use the [testers](https://anirban166.github.io/testComplexity/articles/Example.html#testers) for verifying the theoretically-derived/empirically-obtained result, apart from using the previous method.

Note that the worst-case complexity class is currently set to quadratic. Cubic and exponential classes were initially thought of to be included, but since a $O(N^2)$ approach is the limit in practically used algorithms, subsequently higher complexity classes were discarded.

If the estimated complexity class turns out to be quadratic, its an indicator that the algorithm could do with a better approach, so as to minimize the computational resources (time/memory).

In such situations, the user may as well want to think of ways to reduce the time complexity, in which case the aforementioned functions will be helpful to continuously give feedback (via re-runs) for each improvement that the user thinks could make a difference in the complexity trend. 
This in turn could potentially lead to improvements in code performance, if such feedback-based optimizations are implemented in order to achieve better computational efficiency.

-------------------------------------------------------------------------------------------------

