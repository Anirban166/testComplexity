if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
return(dt)
}
ats = function(expr(N=4))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
timings$datasetsize <- datasetsizes[i]
if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
return(dt)
}
ats = function(expr(N))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
timings$datasetsize <- datasetsizes[i]
if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
return(dt)
}
ats = function(f=function(N))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
timings$datasetsize <- datasetsizes[i]
if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
return(dt)
}
ats = function(f(N))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
timings$datasetsize <- datasetsizes[i]
if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
return(dt)
}
ats = function(expr(N, RN = NULL))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
timings$datasetsize <- datasetsizes[i]
if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
return(dt)
}
ats = function(expr(Ns, RN = NULL), N)
{
datasetsizes <- c(10^seq(1,N,by=0.5))
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
timings$datasetsize <- datasetsizes[i]
if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
return(dt)
}
ats = function(expr, N)
{
datasetsizes <- c(10^seq(1,N,by=0.5))
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
timings$datasetsize <- datasetsizes[i]
if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
return(dt)
}
ats = function(expr(size, RN = NULL), N)
{
datasetsizes <- c(10^seq(1,N,by=0.5))
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
timings$datasetsize <- datasetsizes[i]
if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
return(dt)
}
asymptoticTimings = function(expr, N, RN=NULL)
{
exprname <- as.character(substitute(expr))
# if(!is.null(RN)) use RN
# else use datasetsizes
datasetsizes <- c(10^seq(1,N,by=0.5))
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
timings$datasetsize <- datasetsizes[i]
if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
return(dt)
}
asymptoticTimings(PeakSegPDPA(rpois(N,10),max.segments=3L),N=3)
datasetsizes <- c(10^seq(1,3,by=0.5))
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(PeakSegPDPA(rpois(datasetsizes[i],10),max.segments=3L)))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
timings$datasetsize <- datasetsizes[i]
if(i!=1)
{  combinator<-rbind(combinator, timings) }
}
dt <- data.table(combinator)
dt
combinator
options(max.print=1000)
combinator
options(max.print=3000)
combinator
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(PeakSegPDPA(rpois(datasetsizes[i],10),max.segments=3L)))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column datasetsize for first run
combinator <- timings
}
# timings$datasetsize <- datasetsizes[i]
else
{ timings$datasetsize <- datasetsizes[i]
combinator<-rbind(combinator, timings)
}
}
combinator
clear
clear()
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(PeakSegPDPA(rpois(datasetsizes[i],10),max.segments=3L)))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column 'datasetsize' and append the first datasetsize (10) to observations 1-100.
result <- timings # create a data frame which holds the data frame with columns expr, timings and datasetsize.
}
else
{
timings$datasetsize <- datasetsizes[i]
result <-rbind(result, timings)
}
}
dt <- data.table(result)
result
rm(list=ls)
rm(list=ls())
timings <- as.data.frame(microbenchmark("PeakSegPDPA" = PeakSegPDPA(rpois(datasetsizes[i],10),max.segments=3L)))
timings <- as.data.frame(microbenchmark("PeakSegPDPA" = PeakSegPDPA(rpois(100,10),max.segments=3L)))
timings
timings <- as.data.frame(microbenchmark("PeakSegPDPA" = PeakSegPDPA(rpois(100,10),max.segments=3L)))
expr = "Peak"
timings <- as.data.frame(microbenchmark(expr = PeakSegPDPA(rpois(100,10),max.segments=3L)))
timings
rm(list=ls())
datasetsizes <- c(10^seq(1,3,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(PeakSegPDPA(rpois(datasetsizes[i],10),max.segments=3L)))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column 'datasetsize' and append the first datasetsize (10) to observations 1-100.
result <- timings # create a data frame which holds the data frame with columns expr, timings and datasetsize.
}
else
{
timings$datasetsize <- datasetsizes[i]
result <-rbind(result, timings)
}
}
dt <- data.table(result)
result
timings$datasetsize <- datasetsizes[i]
asymptoticTimings = function(expr, N)
{
datasetsizes <- c(10^seq(1,N,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i]
result <- timings
}
else
{
timings$datasetsize <- datasetsizes[i]
result <- rbind(result, timings)
}
}
dt <- data.table(result)
return(dt)
}
library(PeakSegDP)
library(PeakSegOptimal)
library(ggplot2)
library(microbenchmark)
require(dplyr)
library(data.table)
asymptoticTimings(PeakSegPDPA(rpois(10,10),max.segments=3L))
asymptoticTimings(PeakSegPDPA(rpois(10,10),max.segments=3L),10)
asymptoticTimings(PeakSegPDPA(rpois(3,10),max.segments=3L),10)
asymptoticTimings(PeakSegPDPA(rpois(3,10),max.segments=3L),3)
asymptoticTimings = function(expr(N))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i]
result <- timings
}
else
{
timings$datasetsize <- datasetsizes[i]
result <- rbind(result, timings)
}
}
dt <- data.table(result)
return(dt)
}
asymptoticTimings = function(function f(N))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i]
result <- timings
}
else
{
timings$datasetsize <- datasetsizes[i]
result <- rbind(result, timings)
}
}
dt <- data.table(result)
return(dt)
}
asymptoticTimings = function(f=function(N))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i]
result <- timings
}
else
{
timings$datasetsize <- datasetsizes[i]
result <- rbind(result, timings)
}
}
dt <- data.table(result)
return(dt)
}
asymptoticTimings = function(expression = expr(N))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i]
result <- timings
}
else
{
timings$datasetsize <- datasetsizes[i]
result <- rbind(result, timings)
}
}
dt <- data.table(result)
return(dt)
}
asymptoticTimings(PeakSegPDPA(rpois(3,10),max.segments=3L))
asymptoticTimings(PeakSegPDPA(rpois(3,10),max.segments=3L), N=5)
asymptoticTimings(PeakSegPDPA(rpois(N=3,10),max.segments=3L))
asymptoticTimings = function(expression = expr(N, RN = NULL))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i]
result <- timings
}
else
{
timings$datasetsize <- datasetsizes[i]
result <- rbind(result, timings)
}
}
dt <- data.table(result)
return(dt)
}
asymptoticTimings = function(expression = expr(N, RN = NULL))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(expr[i]))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i]
result <- timings
}
else
{
timings$datasetsize <- datasetsizes[i]
result <- rbind(result, timings)
}
}
dt <- data.table(result)
return(dt)
}
asymptoticTimings(PeakSegPDPA(rpois(N=3,10),max.segments=3L))
datasetsizes <- c(10^seq(1,3,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(PeakSegPDPA(rpois(datasetsizes[i],10),max.segments=3L)))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column 'datasetsize' and append the first datasetsize (10) to observations 1-100.
result <- timings # create a data frame which holds the data frame with columns expr, timings and datasetsize.
}
else
{
timings$datasetsize <- datasetsizes[i]
result <-rbind(result, timings)
}
}
dt <- data.table(result)
dt
datasetsizes <- c(10^seq(1,3,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(PeakSegPDPA(rpois(datasetsizes[i],10),max.segments=3L)))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column 'datasetsize' and append the first datasetsize (10) to observations 1-100.
result <- timings # create a data frame which holds the data frame with columns expr, timings and datasetsize.
}
else
{
timings$datasetsize <- datasetsizes[i]
result <-rbind(result, timings)
}
}
data.table(result)
at = function(function = f(N))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(f[i]))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column 'datasetsize' and append the first datasetsize (10) to observations 1-100.
result <- timings # create a data frame which holds the data frame with columns expr, timings and datasetsize.
}
else
{
timings$datasetsize <- datasetsizes[i]
result <-rbind(result, timings)
}
}
return(result)
}
at = function(expression = expr(N))
{
datasetsizes <- c(10^seq(1,N,by=0.5))
# total obs. = (N + (N-1))x100. For eg: N=2 -> 300 obs., N=3 -> 500 obs., N=4 -> 700 obs. and so on.
l <- length(datasetsizes)
for(i in 1:l)
{
timings <- as.data.frame(microbenchmark(f[i]))
if(i == 1)
{
timings$datasetsize <- datasetsizes[i] # add column 'datasetsize' and append the first datasetsize (10) to observations 1-100.
result <- timings # create a data frame which holds the data frame with columns expr, timings and datasetsize.
}
else
{
timings$datasetsize <- datasetsizes[i]
result <-rbind(result, timings)
}
}
return(result)
}
